import os
import re
import subprocess
from datetime import datetime
from collections import Counter
from openai import OpenAI

# é…ç½®
API_BASE_URL = "https://api.deepseek.com"
MODEL = "deepseek-chat"

client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
    base_url=API_BASE_URL
)

# æ’é™¤æ–‡ä»¶
EXCLUDE_PATTERNS = [
    r'readme\.md$',
    r'^test\d*\.md$',
    r'^\.obsidian/',
    r'^\.github/',
    r'^Assets/',
    r'^Reviews/',
]


def should_process_file(file_path):
    """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦éœ€è¦å¤„ç†"""
    if not file_path.endswith('.md'):
        return False
    
    file_lower = file_path.lower()
    for pattern in EXCLUDE_PATTERNS:
        if re.search(pattern, file_lower, re.IGNORECASE):
            return False
    
    return True


def has_frontmatter(content):
    """æ£€æŸ¥æ˜¯å¦å·²æœ‰ frontmatter"""
    return content.startswith('---\n') or content.startswith('---\r\n')


def extract_topic(file_path: str) -> str:
    """ä»æ–‡ä»¶åæå– topic"""
    filename = os.path.basename(file_path)
    topic = os.path.splitext(filename)[0]
    return topic


def get_created_time(file_path: str) -> str:
    """è·å–åˆ›å»ºæ—¶é—´ï¼ˆGit æœ€æ—© commitï¼Œç²¾ç¡®åˆ°åˆ†é’Ÿï¼‰"""
    try:
        cmd = ['git', 'log', '--follow', '--format=%aI', '--reverse', '--', file_path]
        result = subprocess.check_output(cmd, text=True).strip()
        
        if result:
            first_commit = result.split('\n')[0]
            dt = datetime.fromisoformat(first_commit.replace('Z', '+00:00'))
            return dt.strftime('%Y-%m-%d %H:%M')
    except Exception as e:
        print(f"  âš ï¸  Git log failed: {e}")
    
    return datetime.now().strftime('%Y-%m-%d %H:%M')


def get_modified_time(file_path: str) -> str:
    """è·å–æœ€åä¿®æ”¹æ—¶é—´ï¼ˆGit æœ€æ–° commitï¼Œç²¾ç¡®åˆ°åˆ†é’Ÿï¼‰"""
    try:
        cmd = ['git', 'log', '-1', '--format=%aI', '--', file_path]
        result = subprocess.check_output(cmd, text=True).strip()
        
        if result:
            dt = datetime.fromisoformat(result.replace('Z', '+00:00'))
            return dt.strftime('%Y-%m-%d %H:%M')
    except Exception as e:
        print(f"  âš ï¸  Git log failed: {e}")
    
    return datetime.now().strftime('%Y-%m-%d %H:%M')


def generate_tags_by_ai(topic: str, content: str, file_path: str) -> list:
    """ä½¿ç”¨ AI ç”Ÿæˆè¯­ä¹‰åŒ–æ ‡ç­¾"""
    
    # å–å‰ 800 å­—ï¼ˆå¢åŠ ä¸Šä¸‹æ–‡ï¼‰
    preview = content[:800]
    
    # æå–è·¯å¾„ä¿¡æ¯ï¼ˆè¾…åŠ© AI ç†è§£ä¸Šä¸‹æ–‡ï¼‰
    path_parts = file_path.split('/')
    context_hint = ""
    if len(path_parts) > 1:
        context_hint = f"\næ–‡ä»¶è·¯å¾„: {'/'.join(path_parts[:-1])}"
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯ç¬”è®°æ ‡ç­¾ç”ŸæˆåŠ©æ‰‹ã€‚

ç¬”è®°æ ‡é¢˜: {topic}{context_hint}
ç¬”è®°å†…å®¹ï¼ˆå‰800å­—ï¼‰:
{preview}

è¯·ä¸ºè¿™ç¯‡ç¬”è®°ç”Ÿæˆ 3-5 ä¸ª**ç²¾å‡†çš„æŠ€æœ¯æ ‡ç­¾**ã€‚

è¦æ±‚ï¼š
1. æ ‡ç­¾åº”è¯¥æ˜¯**æ ¸å¿ƒæŠ€æœ¯æ¦‚å¿µã€æ¡†æ¶åã€æˆ–ä¸“ä¸šæœ¯è¯­**
2. æ¯ä¸ªæ ‡ç­¾ 2-10 ä¸ªå­—ç¬¦
3. ä¼˜å…ˆæå–ï¼š
   - ç¼–ç¨‹è¯­è¨€ï¼ˆJava, Python, JavaScriptï¼‰
   - æ¡†æ¶/åº“ï¼ˆSpring, Vue, React, Redisï¼‰
   - æŠ€æœ¯æ¦‚å¿µï¼ˆIoC, RESTful, å“åº”å¼ï¼‰
   - å·¥å…·ï¼ˆGit, Docker, Mavenï¼‰
4. ä¸­è‹±æ–‡æ··åˆå¯ä»¥ï¼Œä½†ä¿æŒä¸“ä¸š
5. ç›´æ¥è¿”å›æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦ä»»ä½•è§£é‡Š

ç¤ºä¾‹ï¼š
- Spring ç¬”è®° â†’ Spring, IoC, ä¾èµ–æ³¨å…¥, Java
- Git ç¬”è®° â†’ Git, ç‰ˆæœ¬æ§åˆ¶, è¿œç¨‹ä»“åº“
- Vue ç¬”è®° â†’ Vue3, å“åº”å¼, Composition API, JavaScript
- ç®—æ³•ç¬”è®° â†’ ç®—æ³•, åŠ¨æ€è§„åˆ’, æ—¶é—´å¤æ‚åº¦

æ ‡ç­¾:"""
    
    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸“ä¸šçš„æŠ€æœ¯æ ‡ç­¾ç”ŸæˆåŠ©æ‰‹ï¼Œç²¾å‡†æå–æ ¸å¿ƒæŠ€æœ¯æ¦‚å¿µæ ‡ç­¾ã€‚"
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=60
        )
        
        tags_str = response.choices[0].message.content.strip()
        
        # æ¸…ç†æ ¼å¼
        tags_str = re.sub(r'^(æ ‡ç­¾|Tags?)[ï¼š:ï¼š\s]*', '', tags_str, flags=re.IGNORECASE)
        tags_str = tags_str.strip('[](){}ã€Œã€ã€Šã€‹""\'`')
        
        # åˆ†å‰²æ ‡ç­¾
        tags = [t.strip() for t in re.split(r'[,ï¼Œã€;ï¼›]', tags_str) if t.strip()]
        
        # è¿‡æ»¤ï¼šé•¿åº¦ 2-10ï¼Œæœ€å¤š 5 ä¸ª
        tags = [t for t in tags if 2 <= len(t) <= 10][:5]
        
        if tags:
            print(f"  ğŸ¤– AI tags: {tags}")
            return tags
        else:
            raise ValueError("AI returned empty tags")
    
    except Exception as e:
        print(f"  âš ï¸  AI failed ({e}), using fallback")
        return fallback_tags(topic, content, file_path)


def extract_keywords_from_content(content: str, top_n=15) -> list:
    """
    ä»å†…å®¹ä¸­æå–é«˜é¢‘æŠ€æœ¯å…³é”®è¯
    
    æ”¹è¿›ï¼š
    1. æå–é©¼å³°å‘½åï¼ˆSpringBoot, MyBatisï¼‰
    2. æå–å¤§å†™ç¼©å†™ï¼ˆIoC, API, HTTPï¼‰
    3. æå–ä¸­æ–‡æŠ€æœ¯è¯ï¼ˆä¾èµ–æ³¨å…¥ã€æ§åˆ¶åè½¬ï¼‰
    4. ç»Ÿè®¡é¢‘ç‡ï¼Œè¿”å›é«˜é¢‘è¯
    """
    
    # ç§»é™¤ä»£ç å—å’Œè¡Œå†…ä»£ç 
    text = re.sub(r'```.*?```', '', content, flags=re.DOTALL)
    text = re.sub(r'`[^`]+`', '', text)
    
    keywords = []
    
    # 1. æå–é©¼å³°å‘½åï¼ˆSpringBoot, MyBatis, ArrayListï¼‰
    camel_case = re.findall(r'\b[A-Z][a-z]+(?:[A-Z][a-z]+)+\b', text)
    keywords.extend(camel_case)
    
    # 2. æå–å¤§å†™ç¼©å†™ï¼ˆIoC, API, HTTP, REST, 2-6 ä¸ªå­—æ¯ï¼‰
    acronyms = re.findall(r'\b[A-Z]{2,6}\b', text)
    keywords.extend(acronyms)
    
    # 3. æå–é¦–å­—æ¯å¤§å†™å•è¯ï¼ˆSpring, Java, Gitï¼‰
    capitalized = re.findall(r'\b[A-Z][a-z]{2,12}\b', text)
    keywords.extend(capitalized)
    
    # 4. æå–ä¸­æ–‡æŠ€æœ¯è¯ï¼ˆ2-6 ä¸ªå­—ï¼‰
    chinese_terms = re.findall(r'[\u4e00-\u9fa5]{2,6}', text)
    keywords.extend(chinese_terms)
    
    # ç»Ÿè®¡é¢‘ç‡
    word_freq = Counter(keywords)
    
    # è¿‡æ»¤åœç”¨è¯
    stopwords = {
        # ä¸­æ–‡
        'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'æœ‰', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'è¿™ä¸ª', 'é‚£ä¸ª',
        'å¯ä»¥', 'éœ€è¦', 'å¦‚æœ', 'å› ä¸º', 'æ‰€ä»¥', 'ä½†æ˜¯', 'ç„¶å', 'å°±æ˜¯', 'ä¸€ä¸ª',
        'æˆ‘ä»¬', 'å®ƒä»¬', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'è¿™æ ·', 'é‚£æ ·',
        # è‹±æ–‡
        'The', 'This', 'That', 'These', 'Those', 'And', 'But', 'For', 'With',
        'From', 'Into', 'When', 'Where', 'Which', 'What', 'How', 'Why',
        'Can', 'Will', 'Should', 'Would', 'Could', 'May', 'Might',
    }
    
    # è¿‡æ»¤
    filtered = [
        word for word, count in word_freq.most_common(top_n * 2)
        if word not in stopwords and len(word) >= 2
    ]
    
    return filtered[:top_n]


def extract_technical_keywords(file_path: str, topic: str, content: str) -> list:
    """
    ç»¼åˆæå–æŠ€æœ¯å…³é”®è¯
    
    æ¥æºï¼š
    1. æ–‡ä»¶è·¯å¾„ï¼ˆJavaNotes/SSM â†’ Java, SSMï¼‰
    2. æ–‡ä»¶åï¼ˆSpringBoot â†’ Spring, Bootï¼‰
    3. å†…å®¹é«˜é¢‘è¯
    """
    
    keywords = []
    
    # 1. ä»è·¯å¾„æå–
    path_parts = file_path.split('/')
    for part in path_parts[:-1]:  # æ’é™¤æ–‡ä»¶å
        # æå–ç›®å½•åä¸­çš„æŠ€æœ¯è¯
        tech_words = re.findall(r'[A-Z][a-z]+|[A-Z]{2,}', part)
        keywords.extend(tech_words)
    
    # 2. ä»æ–‡ä»¶åæå–
    # "SpringBoot" â†’ ["Spring", "Boot"]
    # "MySQL" â†’ ["MySQL"]
    topic_words = re.findall(r'[A-Z][a-z]+|[A-Z]{2,}', topic)
    keywords.extend(topic_words)
    
    # 3. ä»å†…å®¹æå–é«˜é¢‘è¯
    content_keywords = extract_keywords_from_content(content, top_n=10)
    keywords.extend(content_keywords)
    
    # å»é‡ï¼ˆä¿æŒé¡ºåºï¼‰
    seen = set()
    unique_keywords = []
    for kw in keywords:
        kw_lower = kw.lower()
        if kw_lower not in seen and len(kw) >= 2:
            seen.add(kw_lower)
            unique_keywords.append(kw)
    
    return unique_keywords


def match_tech_categories(keywords: list, content: str) -> list:
    """
    åŒ¹é…æŠ€æœ¯åˆ†ç±»æ ‡ç­¾
    
    æ ¹æ®å…³é”®è¯å’Œå†…å®¹ï¼Œæ¨æ–­æŠ€æœ¯æ ˆåˆ†ç±»
    """
    
    categories = []
    
    # æŠ€æœ¯åˆ†ç±»è§„åˆ™
    tech_map = {
        # ç¼–ç¨‹è¯­è¨€
        'Java': ['java', 'jvm', 'spring', 'maven', 'mybatis'],
        'Python': ['python', 'django', 'flask', 'numpy', 'pandas'],
        'JavaScript': ['javascript', 'js', 'node', 'vue', 'react', 'typescript'],
        
        # æ¡†æ¶
        'Spring': ['spring', 'springboot', 'ioc', 'aop', 'mvc'],
        'Vue': ['vue', 'vuex', 'router', 'å“åº”å¼', 'composition'],
        'React': ['react', 'jsx', 'hooks', 'redux'],
        
        # æ•°æ®åº“
        'MySQL': ['mysql', 'sql', 'æ•°æ®åº“', 'select', 'join'],
        'Redis': ['redis', 'ç¼“å­˜', 'nosql', 'key-value'],
        
        # å·¥å…·
        'Git': ['git', 'github', 'commit', 'branch', 'ç‰ˆæœ¬æ§åˆ¶'],
        'Docker': ['docker', 'å®¹å™¨', 'dockerfile', 'compose'],
        'Linux': ['linux', 'shell', 'bash', 'ubuntu', 'centos'],
        
        # æ¦‚å¿µ
        'API': ['api', 'rest', 'restful', 'http', 'æ¥å£'],
        'ç®—æ³•': ['ç®—æ³•', 'algorithm', 'æ—¶é—´å¤æ‚åº¦', 'åŠ¨æ€è§„åˆ’', 'æ’åº'],
        'è®¾è®¡æ¨¡å¼': ['è®¾è®¡æ¨¡å¼', 'pattern', 'å•ä¾‹', 'å·¥å‚', 'è§‚å¯Ÿè€…'],
    }
    
    # ç»„åˆæ‰€æœ‰æ–‡æœ¬ï¼ˆå°å†™ï¼‰
    all_text = ' '.join(keywords).lower() + ' ' + content.lower()
    
    # åŒ¹é…
    for category, patterns in tech_map.items():
        for pattern in patterns:
            if pattern in all_text:
                if category not in categories:
                    categories.append(category)
                break
    
    return categories


def fallback_tags(topic: str, content: str, file_path: str) -> list:
    """
    å®Œå–„çš„å…œåº•è§„åˆ™
    
    ç­–ç•¥ï¼š
    1. æå–æŠ€æœ¯å…³é”®è¯ï¼ˆè·¯å¾„ + æ–‡ä»¶å + å†…å®¹ï¼‰
    2. åŒ¹é…æŠ€æœ¯åˆ†ç±»
    3. ç»„åˆå»é‡
    4. æ™ºèƒ½æ’åºï¼ˆä¼˜å…ˆçº§ï¼šåˆ†ç±» > å…³é”®è¯ï¼‰
    """
    
    print(f"  ğŸ“ Using fallback rules...")
    
    # 1. æå–æ‰€æœ‰æŠ€æœ¯å…³é”®è¯
    keywords = extract_technical_keywords(file_path, topic, content)
    
    # 2. åŒ¹é…æŠ€æœ¯åˆ†ç±»
    categories = match_tech_categories(keywords, content)
    
    # 3. ç»„åˆ tagsï¼ˆåˆ†ç±»ä¼˜å…ˆï¼‰
    tags = []
    
    # ä¼˜å…ˆåŠ åˆ†ç±»æ ‡ç­¾
    tags.extend(categories[:3])
    
    # è¡¥å……å…³é”®è¯ï¼ˆé¿å…é‡å¤ï¼‰
    for kw in keywords:
        if kw not in tags and len(tags) < 5:
            tags.append(kw)
    
    # 4. å¦‚æœè¿˜æ˜¯ç©ºï¼Œç”¨æ–‡ä»¶å
    if not tags:
        tags = [topic]
    
    print(f"  ğŸ“ Fallback tags: {tags[:5]}")
    return tags[:5]


def generate_frontmatter(file_path: str, content: str) -> str:
    """ç”Ÿæˆ frontmatter"""
    
    print(f"\nğŸ“„ {file_path}")
    
    # 1. Topicï¼šæ–‡ä»¶å
    topic = extract_topic(file_path)
    print(f"  ğŸ“ Topic: {topic}")
    
    # 2. æ—¶é—´ï¼šä» Git è·å–
    created = get_created_time(file_path)
    modified = get_modified_time(file_path)
    print(f"  ğŸ“… Created: {created}")
    print(f"  ğŸ“… Modified: {modified}")
    
    # 3. Tagsï¼šä¼˜å…ˆ AIï¼Œå¤±è´¥åˆ™ç”¨å®Œå–„çš„è§„åˆ™
    tags = generate_tags_by_ai(topic, content, file_path)
    
    # æ„å»º frontmatter
    frontmatter = f"""---
topic: {topic}
created: {created}
modified: {modified}
tags: [{', '.join(tags)}]
---

"""
    
    return frontmatter


def process_file(file_path: str) -> bool:
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"  âŒ Read error: {e}")
        return False
    
    if has_frontmatter(content):
        print(f"  â­ï¸  Skip (already has frontmatter)")
        return False
    
    frontmatter = generate_frontmatter(file_path, content)
    
    new_content = frontmatter + content
    
    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        print(f"  âœ… Added")
        return True
    except Exception as e:
        print(f"  âŒ Write error: {e}")
        return False
        
def main():
    print("=" * 70)
    print("ğŸ”§ Frontmatter AutoWired")
    print("=" * 70)
    
    # é…ç½® Git æ­£ç¡®å¤„ç†ä¸­æ–‡æ–‡ä»¶å
    try:
        subprocess.run(
            ['git', 'config', 'core.quotepath', 'false'],
            check=False,
            capture_output=True
        )
    except:
        pass  # å¿½ç•¥é…ç½®å¤±è´¥
    
    # è·å–å˜æ›´çš„ .md æ–‡ä»¶
    try:
        cmd = ['git', 'diff', '--name-only', 'HEAD~1', 'HEAD', '--', '*.md']
        result = subprocess.check_output(
            cmd, 
            text=True, 
            encoding='utf-8'  # ç¡®ä¿ä½¿ç”¨ UTF-8
        ).strip()
        
        print(f"\nğŸ” Git diff result:")
        print(f"{result}")
        
        if not result:
            print("\nâš ï¸  No .md files changed in last commit")
            return
        
        files = result.split('\n')
        print(f"\nğŸ“ Files from git diff: {files}")
        
    except Exception as e:
        print(f"\nâŒ Git diff failed: {e}")
        print("âš ï¸  Falling back to processing all .md files")
        files = []
        for root, dirs, filenames in os.walk('.'):
            for filename in filenames:
                if filename.endswith('.md'):
                    file_path = os.path.join(root, filename).lstrip('./')
                    files.append(file_path)
    
    # è¿‡æ»¤
    files = [f for f in files if should_process_file(f)]
    
    if not files:
        print("\nâš ï¸  No files to process (after filtering)")
        print(f"   Exclusion patterns: {EXCLUDE_PATTERNS}")
        return
    
    print(f"\nğŸ“Š Files to process: {len(files)}")
    print("ğŸ¤– AI mode: enabled (all files)")
    
    # å¤„ç†
    processed = 0
    for file in files:
        if process_file(file):
            processed += 1
    
    print("\n" + "=" * 70)
    print(f"âœ… Processed: {processed}/{len(files)}")
    print("=" * 70)


if __name__ == "__main__":
    main()
